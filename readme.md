# ğŸš• NYC Taxi Data Engineering Project  
### Modern Medallion Architecture | Docker â€¢ Airflow â€¢ dbt â€¢ Azure SQL â€¢ Power BI

---
## ğŸ—ï¸ Architecture

![Architecture Diagram](./screenshots/architecture.png)

## ğŸ“ Project Overview

This end-to-end data engineering project implements a **modern Medallion Architecture (Bronze â†’ Silver â†’ Gold)** using:

- **Apache Airflow** for workflow orchestration  
- **dbt Core** for SQL-first transformations & data quality  
- **Docker** for a fully reproducible local environment  
- **Azure Storage + Azure SQL Database** as the cloud data layer  
- **Power BI** for business-ready dashboards  

The pipeline processes **NYC Yellow Taxi Trip Data for August 2025**, performing **ingestion â†’ transformation â†’ aggregation â†’ visualization**.


---

## ğŸ† Key Achievements

- âš™ï¸ **End-to-end pipeline** orchestrated via Airflow (ingest â†’ dbt run â†’ dbt test)  
- ğŸ”— **Fully modular Medallion Architecture** (raw â†’ cleaned â†’ analytics-ready marts)  
- ğŸ§ª **Data Quality Framework** using dbt tests (unique, not null, accepted values, relationships)  
- ğŸ³ **Reproducible Development Environment** (single `docker compose up`)  
- â˜ï¸ **Cloud integration with Azure SQL** for production-ready storage  
- ğŸ“Š **Power BI Dashboard** built directly from the Gold layer  
- ğŸš€ **Airflow DAG automation** with task dependencies. 

---


## ğŸ§° Tech Stack

- **Orchestration:** Apache Airflow (Dockerized)
- **Transformation:** dbt Core + SQL Server adapter
- **Storage:** Azure Blob Storage (Bronze), Azure SQL Database (Silver/Gold)
- **Containerization:** Docker Compose
- **Data Processing:** Python, pandas
- **Visualization:** Power BI
- **Version Control:** Git + GitHub

---

## ğŸ“‚ Repository Structure
```
â”€â”€ airflow/
    â”œâ”€â”€ dags/
    â”‚   â””â”€â”€ taxi_pipeline_dag.py
    â”œâ”€â”€ dbt_profile/
    â”‚   â”œâ”€â”€ .user.yml
    â”‚   â”œâ”€â”€ profiles.yml       
    â”œâ”€â”€ dbt_project/
    â”‚   â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ target/
    â”‚   â”œâ”€â”€ dbt_project.yml
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ dockerfile
    â”œâ”€â”€ load_raw_to_sql.py
    â”œâ”€â”€ upload_to_blob.py
    â”œâ”€â”€ readme.md
    â””â”€â”€ screenshots/
        â”œâ”€â”€ architecture.png
        â”œâ”€â”€ airflow_homepage.png
        â”œâ”€â”€ dag_dbt_run.png
        â”œâ”€â”€ dag_graph_view.png
        â”œâ”€â”€ dag_overview.png
        â”œâ”€â”€ dashboard.png
        â”œâ”€â”€ lineage_taxi.png

```

## ğŸ”„ Data Pipeline Steps

### **1. Raw Ingestion (Bronze Layer)**
- `upload_to_blob.py` uploads the raw Parquet file into **Azure Blob Storage (Bronze layer)**.  
- `load_raw_to_sql.py`, executed by Airflow, reads data from Blob and loads it into **Azure SQL (`raw` schema)**.  
- **Airflow task:** `ingest_raw`

---

### **2. dbt Staging Layer (`stg_trips`)**
- Casts raw CSV/Parquet fields into proper SQL types (ints, decimals, datetimes).  
- Normalizes values (e.g. `store_and_fwd_flag`).  
- Filters out invalid records (negative distances/amounts, null timestamps, inconsistent pickup/dropoff times).  
- Provides a clean, typed base table for downstream models.  

**Airflow task:** `dbt_run`

---

### **3. dbt Silver Layer**
- Builds an analytics-friendly trips table from the staging layer.  
- Adds derived features: trip duration, pickup date/hour, weekday, tip percentage.  
- Uses small dimension tables (e.g. payment type descriptions) to normalize categorical fields.  

**Airflow task:** `dbt_run`

---

### **4. dbt Gold Layer**
Creates analytic marts:

- `mart_daily_revenue`
- `mart_trips_by_hour`
- `mart_zone_revenue`
- `mart_tip_by_payment_type`

These tables are consumed by **Power BI**.

---

### **5. Data Quality (dbt tests)**
- `unique` tests  
- `not_null` tests on critical fields (timestamps, amounts, keys).  
- `accepted_values` tests on categorical fields (rate codes, payment types).  
- Relationship tests between dimensions and facts . 

**Airflow task:** `dbt_test`

---

### **6. Power BI Dashboard**
- Connected directly to **Azure SQL Gold tables**  
- Used for reporting and visualization  

## ğŸ“¸ Screenshots

### **Airflow DAG (Graph View)**
![DAG Graph](./screenshots/dag_graph_view.png)

### **Airflow DAG Overview**
![DAG Overview](./screenshots/dag_overview.png)

### **Airflow dbt Run Task**
![dbt Run](./screenshots/dag_dbt_run.png)

### **dbt Lineage Graph**
![dbt Lineage](./screenshots/lineage_taxi.png)

### **Power BI Dashboard**
![Dashboard](./screenshots/dashboard.png)

## ğŸ“ Key Learnings

- Designed and implemented a full **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** on Azure.  
- Learned how to build and schedule a production-style pipeline using **Apache Airflow**.  
- Gained hands-on experience with **dbt Core**, creating modular SQL models, refactoring transformations, and maintaining lineage.  
- Applied **data quality frameworks** using dbt tests (`unique`, `not_null`, `relationships`, `accepted_values`).  
- Built a fully reproducible **Dockerized analytics engineering environment** using `docker compose`.  
- Understood how to integrate cloud storage and compute through **Azure Blob Storage** and **Azure SQL Database**.  
- Modeled clean **Gold layer marts** optimized for BI consumption.  
- Created a **Power BI dashboard** connected directly to Azure SQL, demonstrating the end-to-end value of the pipeline.  

